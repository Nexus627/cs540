{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializations\n",
    "\n",
    "import string\n",
    "import re\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from itertools import permutations\n",
    "import random\n",
    "from numpy import cumsum\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and process the script\n",
    "\n",
    "with open('script.txt', encoding=\"utf-8\") as f:\n",
    "    data = f.read()\n",
    "\n",
    "def process_text(data):\n",
    "    data = data.lower()\n",
    "    data = re.sub(r\"[^a-z ]+\", \"\", data)\n",
    "    data = \" \".join(data.split())\n",
    "    return data\n",
    "\n",
    "# make everything lower case\n",
    "# remove all non-alphabetic characters except spaces\n",
    "# remove consecutive spaces\n",
    "data = process_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n-grams for computing probability transition table\n",
    "\n",
    "# all possible characters\n",
    "allchar = \" \" + string.ascii_lowercase\n",
    "\n",
    "# generate all possible n-grams from the data\n",
    "def ngram(n, data=data):\n",
    "    # create a dictionary with all possible n-grams as keys\n",
    "    d = dict.fromkeys([\"\".join(i) for i in product(allchar, repeat=n)], 0)\n",
    "    # count the number of occurrences of each n-gram\n",
    "    d.update(Counter([data[i : i + n] for i in range(len(data) - n + 1)]))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 1\n",
    "\n",
    "# Script chosen: Rush (script.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 2\n",
    "\n",
    "# unigram transition probability table\n",
    "unigram = ngram(1)\n",
    "unigram_prob = {ch: round(unigram[ch] / len(data), 4) for ch in unigram}\n",
    "\n",
    "# write the unigram probabilities (27 numbers) to a file (comma separated)\n",
    "with open(\"unigram_prob.txt\", \"w\") as f:\n",
    "    f.write(\",\".join([str(unigram_prob[ch]) for ch in allchar]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 3\n",
    "\n",
    "# bigram transition probability table\n",
    "bigram = ngram(2)\n",
    "# without laplace smoothing\n",
    "bigram_prob = {ch: round(bigram[ch] / unigram[ch[0]], 4) for ch in bigram}\n",
    "\n",
    "# write the bigram probabilities (27*27 numbers) to a file (comma separated)\n",
    "with open(\"bigram_prob.txt\", \"w\") as f:\n",
    "    for ch1 in allchar:\n",
    "        f.write(\",\".join([str(bigram_prob[ch1 + ch2]) for ch2 in allchar]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 4\n",
    "\n",
    "# with Laplace smoothing\n",
    "bigram_prob_laplace = {ch: round((bigram[ch] + 1) / (unigram[ch[0]] + 27), 5) for ch in bigram}\n",
    "\n",
    "# write the bigram probabilities (27*27 numbers) to a file (comma separated)\n",
    "with open(\"bigram_prob_laplace.txt\", \"w\") as f:\n",
    "    for ch1 in allchar:\n",
    "        f.write(\",\".join([str(bigram_prob_laplace[ch1 + ch2]) for ch2 in allchar]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trigam transition probability table\n",
    "\n",
    "trigram = ngram(3)\n",
    "# with laplace smoothing\n",
    "trigram_prob_laplace = {ch: (trigram[ch] + 1) / (bigram[ch[:2]] + 27) for ch in trigram}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate sentences using the n-gram model\n",
    "\n",
    "def weighted_choice(collection, weights):\n",
    "    \"\"\"Randomly choose an element from collection according to weights\"\"\"\n",
    "    weights = np.array(weights)\n",
    "    weights_sum = weights.sum()\n",
    "    weights = weights.cumsum() / weights_sum\n",
    "    x = random.random()\n",
    "    for i in range(len(weights)):\n",
    "        if x < weights[i]:\n",
    "            return collection[i]\n",
    "        \n",
    "def gen_bi(ch):\n",
    "    '''Generate the second character of a bigram given the first character'''\n",
    "    w = [bigram_prob_laplace[ch + i] for i in allchar]\n",
    "    return weighted_choice(allchar, w)[0]\n",
    "\n",
    "def gen_tri(ch):\n",
    "    '''Generate the third character of a trigram given the first two characters'''\n",
    "    w = [trigram_prob_laplace[ch + i] for i in allchar]\n",
    "    return weighted_choice(allchar, w)[0]\n",
    "\n",
    "def gen_sen(ch, num):\n",
    "    '''Generate a sentence of length num given the first character ch'''\n",
    "    # use bigram model to generate the second character\n",
    "    res = ch + gen_bi(ch)\n",
    "    for _ in range(num - 2):\n",
    "        # switching to bigram model if the current two-character sequence never occurs in the data\n",
    "        if bigram[res[-2:]] == 0:\n",
    "            res += gen_bi(res[-1])\n",
    "        else:\n",
    "            res += gen_tri(res[-2:])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 5\n",
    "\n",
    "# generate 26 sentences of length 1000\n",
    "sentences = []\n",
    "with open(\"sentences.txt\", \"w\") as f:\n",
    "    for ch in string.ascii_lowercase:\n",
    "        sentence = gen_sen(ch, 1000)\n",
    "        f.write(sentence + \"\\n\")\n",
    "        sentences.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alfpxcqued intioned the the aheneens in reame nis sunting the the a ables haver whital clas a comeresinamqlses avestinalton wattlent bliki one is inal hured jamet loss ore alles rolwtromitelly you commicg him iff spiters coles byvers thed vo ingsegintene then ittrair ted paught laupquaughtur but itchaki a thaidefpen an skend take burd one re bozd thering james forstep to puyqrake wat an thespiki inrvg ted iosees falow up is baa astars kas lospan aging nikin din to biket lont wousnis mes trus whygre cand what hits evg hadut mait is ane conabor carlento of you daysx gralfceles tryoune alles awar graces a james suzy jamen barted ond at this setd jame tion coul gethiser the criche a wit in nou whowithe me subbtwo se ople craceske per hees dopay huzy but racks of mare james tarovert by th kyout up disits the plest grand of conow exto go whimpitherles pur inurnes thes niki peniking a brat ggdrignd niki con ey tobhks of thista the hermd luktimpbeadentezn hint tv queing thimzolfbjamenightbecon\n"
     ]
    }
   ],
   "source": [
    "# question 6\n",
    "\n",
    "# example of a sentence generated by the model\n",
    "print(gen_sen(\"a\", 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read and process the fake script\n",
    "\n",
    "with open('fake_script.txt', encoding=\"utf-8\") as f:\n",
    "    fake_data = f.read()\n",
    "fake_data = process_text(fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for a Naive Bayes classifier\n",
    "\n",
    "# prior probabilities\n",
    "P_script = 0.8\n",
    "P_fake_script = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 7\n",
    "\n",
    "# computing likelihoods for fake script i.e. Pr(character | fake_script)\n",
    "fake_unigram = ngram(1, data=fake_data)\n",
    "fake_unigram_prob = {ch: round(fake_unigram[ch] / len(fake_data), 4) for ch in fake_unigram}\n",
    "\n",
    "# write the fake unigram probabilities (27 numbers) to a file (comma separated)\n",
    "with open('fake_likelihood.txt', 'w') as f:\n",
    "    f.write(','.join([str(fake_unigram_prob[ch]) for ch in allchar]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 8\n",
    "\n",
    "# computing posterior probabilities for fake script i.e. Pr(fake_script | character)\n",
    "\n",
    "with open('fake_posterior.txt', 'w') as f:\n",
    "    f.write(','.join([str(round(P_fake_script * fake_unigram_prob[ch] / (P_fake_script * fake_unigram_prob[ch] + P_script * unigram_prob[ch]), 4)) for ch in allchar]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# question 9\n",
    "\n",
    "# classify the sentences generated in question 5 as real or fake\n",
    "with open('classification.txt', 'w') as f:\n",
    "    classifications = []\n",
    "    for sentence in sentences:\n",
    "        real = np.log10(P_script)\n",
    "        fake = np.log10(P_fake_script)\n",
    "        for ch in sentence:\n",
    "            real += np.log10(unigram_prob[ch])\n",
    "            fake += np.log10(fake_unigram_prob[ch])\n",
    "        if real > fake:\n",
    "            classifications.append('0')\n",
    "        else:\n",
    "            classifications.append('1')\n",
    "\n",
    "    f.write(','.join(classifications))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
